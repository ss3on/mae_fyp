{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-31T14:49:02.974153Z",
     "start_time": "2025-08-31T14:49:02.954664Z"
    }
   },
   "source": [
    "from src.file_handling import file_location\n",
    "\n",
    "data = file_location.FolderPathOfASME()\n",
    "data_path = data.data\n",
    "md_path = data.asme_jmd / 'markdown'\n",
    "embeddings_path = data.asme_jmd / 'embeddings'"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for md in md_path.rglob('*.md'):\n",
    "    test_md = md\n",
    "    break\n",
    "\n",
    "from markdownify import markdownify as md_to_text\n",
    "\n",
    "with open(test_md, \"r\", encoding=\"utf-8\") as f:\n",
    "    markdown_content = f.read()\n",
    "\n",
    "plain_text, doi = md_to_text(markdown_content), test_md.stem"
   ],
   "id": "d835fda439098876",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"globuslabs/ScholarBERT-XL\", add_pooling_layer=False)\n",
    "model = AutoModel.from_pretrained(\"globuslabs/ScholarBERT-XL\", dtype=torch.float16).to(\"cuda\")\n",
    "model.eval()\n",
    "\n",
    "inputs = tokenizer(plain_text, return_tensors=\"pt\", truncation=True, padding=True).to(\"cuda\")\n",
    "\n",
    "def get_embedding(texts):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        pooled = outputs.last_hidden_state.mean(dim=1).cpu().half()\n",
    "    return pooled"
   ],
   "id": "c3cdc3240d8ce098",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for md in md_path.rglob('*.md'):\n",
    "    doi = md.stem\n",
    "    print(md)"
   ],
   "id": "55dd0607c69878c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T15:13:12.935188Z",
     "start_time": "2025-08-31T15:13:12.932844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "def load_embedding(doi: str, file_path: Path):\n",
    "    \"\"\"\n",
    "    Loads a saved embedding tensor from disk using DOI.\n",
    "    \"\"\"\n",
    "    if not file_path.exists():\n",
    "        print(f\"⚠️ Embedding file not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        embedding = torch.load(file_path)\n",
    "        print(f\"✅ Loaded embedding: {file_path}\")\n",
    "        return embedding\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load embedding for {doi}: {e}\")\n",
    "        return None\n"
   ],
   "id": "56e4c9f012ad31c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T15:18:19.148771Z",
     "start_time": "2025-08-31T15:18:19.134861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for emb in (data.asme_jmd / 'embeddings' / 'fp32') .rglob('*.pt'):\n",
    "    print(emb)\n",
    "    test = load_embedding(emb.stem, emb)\n",
    "    break\n",
    "test.dtype"
   ],
   "id": "896e6d74c962dcf9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\One Drives\\OneDrive - Nanyang Technological University\\Academics\\fyp\\data\\asme_jmd\\embeddings\\fp32\\doi_10.1115_1.1286084.pt\n",
      "✅ Loaded embedding: F:\\One Drives\\OneDrive - Nanyang Technological University\\Academics\\fyp\\data\\asme_jmd\\embeddings\\fp32\\doi_10.1115_1.1286084.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
